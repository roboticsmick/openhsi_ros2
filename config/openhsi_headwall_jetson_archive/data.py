# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/api/data.ipynb.

# %% auto 0
__all__ = [
    "Shape",
    "DType",
    "Array",
    "CircArrayBuffer",
    "CameraProperties",
    "DateTimeBuffer",
    "DataCube",
]

# %% ../nbs/api/data.ipynb 4
from fastcore.foundation import patch
from fastcore.meta import delegates
from fastcore.basics import listify
from fastcore.xtras import *
import os
import xarray as xr
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from scipy.interpolate import interp1d
from PIL import Image
from scipy.signal import decimate

from typing import Iterable, Union, Callable, List, TypeVar, Generic, Tuple, Optional
import json
import pickle
from datetime import datetime, timezone, timedelta
from pathlib import Path
import warnings
import pprint

import holoviews as hv

hv.extension("bokeh", logo=False)

# %% ../nbs/api/data.ipynb 5
# numpy.ndarray type hints
Shape = TypeVar("Shape")
DType = TypeVar("DType")


class Array(np.ndarray, Generic[Shape, DType]):
    """
    Use this to type-annotate numpy arrays, e.g.
        image: Array['H,W,3', np.uint8]
        xy_points: Array['N,2', float]
        nd_mask: Array['...', bool]
    from: https://stackoverflow.com/questions/35673895/type-hinting-annotation-pep-484-for-numpy-ndarray
    """

    pass


# %% ../nbs/api/data.ipynb 7
class CircArrayBuffer:
    """Circular FIFO Buffer implementation on ndarrays. Each put/get is a (n-1)darray."""

    def __init__(
        self,
        size: tuple = (100, 100),  # Shape of n-dim circular buffer to preallocate
        axis: int = 0,  # Which axis to traverse when filling the buffer
        dtype: type = np.uint8,  # Buffer numpy data type
        show_func: Callable[
            [np.ndarray], "plot"
        ] = None,  # Custom plotting function if desired
    ):
        """Preallocate a array of `size` and type `dtype` and init write/read pointer."""
        self.data = np.zeros(size, dtype=dtype)
        self.size = size
        self.axis = axis
        self.write_pos = [
            slice(None, None, None) if i != axis else 0 for i in range(len(size))
        ]
        self.read_pos = self.write_pos.copy()
        self.slots_left = self.size[self.axis]
        self.show_func = show_func

    def __getitem__(self, key: slice):
        return self.data[key]

    def _inc(self, idx: List[slice]) -> List[slice]:
        """Increment read/write index with wrap around"""
        idx[self.axis] += 1
        if idx[self.axis] == self.size[self.axis]:
            idx[self.axis] = 0
        return idx

    def is_empty(self) -> bool:
        return self.slots_left == self.size[self.axis]

    def put(self, line: np.ndarray):
        """Writes a (n-1)darray into the buffer"""
        self.data[tuple(self.write_pos)] = line

        # if buffer full, update read position to keep track of oldest slot
        self.slots_left -= 1
        if self.slots_left < 0:
            self.slots_left = 0
            self.read_pos = self._inc(self.read_pos)

        self.write_pos = self._inc(self.write_pos)

    def get(self) -> np.ndarray:
        """Reads the oldest (n-1)darray from the buffer"""
        if self.slots_left < self.size[self.axis]:
            val = self.data[tuple(self.read_pos)]
            self.slots_left += 1
            self.read_pos = self._inc(self.read_pos)
            return val
        else:
            return None

    def show(self):
        """Display the data"""
        if self.show_func is None:
            if len(self.size) == 2:
                return hv.Image(self.data.copy(), bounds=(0, 0, *self.size)).opts(
                    xlabel="wavelength index", ylabel="cross-track", cmap="gray"
                )
            elif len(self.size) == 3:
                # Sum over the last dimensions (assumed wavelength) and show as monochrome
                return hv.Image(
                    np.sum(self.data, axis=-1), bounds=(0, 0, *self.size[:2])
                ).opts(xlabel="along-track", ylabel="cross-track", cmap="gray")
            elif len(self.size) == 1:
                print(f"#({self.size[0]}) {self.data}")
        elif self.show_func is not None:
            return self.show_func(self.data)
        else:
            print(
                "Unsupported array shape. Please use 2D or 3D shapes or use your own custom show function"
            )


# %% ../nbs/api/data.ipynb 17 (Modify this cell)
class CameraProperties:
    """Save and load OpenHSI camera settings and calibration"""

    def __init__(
        self,
        json_path: str = None,  # Path to settings file
        cal_path: str = None,  # Path to calibration file
        print_settings: bool = False,  # Print out settings file contents
        **kwargs,
    ):
        """Load the settings and calibration files"""
        self.json_path = json_path

        # Handle pkl_path for backwards compatibility
        if "pkl_path" in kwargs:
            if cal_path is not None and cal_path != kwargs["pkl_path"]:
                warnings.warn(
                    "Both 'pkl_path' and 'cal_path' were provided with different values. Using 'cal_path'.",
                    UserWarning,
                    stacklevel=2,
                )
            elif cal_path is None:
                cal_path = kwargs["pkl_path"]
            warnings.warn(
                "'pkl_path' argument is deprecated. Please use 'cal_path' instead.",
                DeprecationWarning,
                stacklevel=2,
            )
        self.cal_path = cal_path

        # Load settings from JSON file
        if json_path:
            if os.path.exists(json_path):
                try:
                    with open(self.json_path) as json_file_handle:
                        self.settings = json.load(json_file_handle)
                except json.JSONDecodeError:
                    print(
                        f"Warning: Could not decode settings JSON file: {self.json_path}. Initializing empty settings."
                    )
                    self.settings = {}
                except Exception as e:
                    print(
                        f"Warning: Error loading settings JSON file {self.json_path}: {e}. Initializing empty settings."
                    )
                    self.settings = {}
            else:
                print(
                    f"Warning: Settings JSON file not found: {self.json_path}. Initializing empty settings."
                )
                self.settings = {}
        else:
            self.settings = {}
            print("No settings JSON path provided. Initializing empty settings.")

        # Override/add settings from kwargs (kwargs take precedence)
        for key, value in kwargs.items():
            if key == "pkl_path":
                continue  # Already handled
            self.settings[key] = value
            if print_settings:
                print(f"Setting from kwarg: {key} = {value}")

        if print_settings:
            print("Final settings after JSON and kwargs:")
            pprint.pprint(self.settings)

        # Initialize self.calibration dictionary
        self.calibration = {}

        # Load calibration data from cal_path (NetCDF or Pickle)
        if cal_path:
            if os.path.exists(cal_path):
                file_extension = os.path.splitext(cal_path)[-1].lower()
                if file_extension in (".pkl", ".pickle"):
                    warnings.warn(
                        f"Pickle (.pkl) calibration file '{cal_path}' is deprecated. "
                        "Please convert to .nc format. Attempting auto-conversion.",
                        DeprecationWarning,
                        stacklevel=2,
                    )
                    try:
                        with open(cal_path, "rb") as handle:
                            loaded_obj = pickle.load(handle)  # Load into temp variable
                            if isinstance(loaded_obj, dict):
                                self.calibration = loaded_obj
                            else:  # Handle case where pickle contains non-dict (e.g. old DataCube)
                                print(
                                    f"Warning: Pickle file {cal_path} did not contain a dictionary. Contained type: {type(loaded_obj)}. Assigning to self.calibration anyway."
                                )
                                self.calibration = (
                                    loaded_obj  # Or handle more gracefully
                                )

                        # Attempt to save to .nc immediately
                        nc_derived_path = os.path.splitext(cal_path)[0] + ".nc"
                        print(
                            f"Successfully loaded PKL {cal_path}. Attempting to save as {nc_derived_path}..."
                        )
                        self.save_calibration_data_to_netcdf(nc_derived_path)
                        print(f"  Successfully saved calibration to {nc_derived_path}")
                        print(
                            f"  Please update your scripts to use this .nc file: {nc_derived_path}"
                        )
                        self.cal_path = nc_derived_path  # Update self.cal_path
                    except Exception as e:
                        raise type(e)(
                            f"Failed to load or convert PKL object from {cal_path}: {e}. "
                            "Issue likely due to changes in dependencies since the pickle file "
                            "was saved. You might need to load and convert it in an older environment."
                        ) from e
                elif file_extension == ".nc":
                    self.load_calibration_data_from_netcdf(cal_path)
                else:
                    raise ValueError(
                        f"Unsupported calibration file type: {file_extension}. Must be .pkl, .pickle, or .nc."
                    )
            else:
                print(
                    f"Warning: Calibration file specified at '{cal_path}' but not found. Initializing empty calibration data."
                )
        else:
            print(
                "No calibration file path provided. Initializing empty calibration data."
            )

        # --- Headwall-specific Wavelength Generation (takes precedence if settings are present) ---
        headwall_params_present = all(
            param in self.settings
            for param in [
                "headwall_pixel_dispersion_nm_px",
                "headwall_pixel0_wavelength_nm",
                "headwall_spectral_offset_fullsensor_px",
                "headwall_spectral_size_px",
            ]
        )

        if headwall_params_present:
            num_spectral_pixels_final = self.settings["headwall_spectral_size_px"]

            # Indices of the *final* spectral pixels relative to the start of the *full sensor's spectral axis*
            abs_pixel_indices_on_sensor = self.settings[
                "headwall_spectral_offset_fullsensor_px"
            ] + np.arange(num_spectral_pixels_final)

            calculated_wavelengths = (
                self.settings["headwall_pixel0_wavelength_nm"]
                + abs_pixel_indices_on_sensor
                * self.settings["headwall_pixel_dispersion_nm_px"]
            )

            self.calibration["wavelengths"] = calculated_wavelengths.astype(np.float32)
            self.calibration["wavelengths_linear"] = calculated_wavelengths.astype(
                np.float32
            )  # It's already linear
            print(
                f"Generated {len(calculated_wavelengths)} wavelengths using Headwall parameters from settings file."
            )
            print(
                f"  Range: {calculated_wavelengths[0]:.2f} nm to {calculated_wavelengths[-1]:.2f} nm"
            )

        elif (
            "wavelengths" not in self.calibration
        ):  # Wavelengths not from cal_path and not generated
            # Fallback: create dummy wavelengths based on "resolution" (which should be final_image_shape_after_crop)
            # This "resolution" is what OpenHSI transforms expect as their input shape.
            final_cropped_resolution = self.settings.get("resolution", None)
            if (
                final_cropped_resolution
                and isinstance(final_cropped_resolution, list)
                and len(final_cropped_resolution) == 2
            ):
                num_spec_pixels_from_res = final_cropped_resolution[1]
                if num_spec_pixels_from_res > 0:
                    self.calibration["wavelengths"] = np.arange(
                        num_spec_pixels_from_res
                    ).astype(np.float32)
                    self.calibration["wavelengths_linear"] = np.arange(
                        num_spec_pixels_from_res
                    ).astype(np.float32)
                    warnings.warn(
                        f"Wavelength information not found in cal_path or Headwall settings. "
                        f"Using dummy indexed wavelengths (0 to {num_spec_pixels_from_res-1}) based on settings['resolution'].",
                        UserWarning,
                        stacklevel=2,
                    )
                else:  # Should not happen with valid settings
                    self.calibration["wavelengths"] = np.array([], dtype=np.float32)
                    self.calibration["wavelengths_linear"] = np.array(
                        [], dtype=np.float32
                    )
            else:  # Absolute fallback if "resolution" is also missing/invalid
                self.calibration["wavelengths"] = np.array([], dtype=np.float32)
                self.calibration["wavelengths_linear"] = np.array([], dtype=np.float32)
                warnings.warn(
                    "Wavelength information not found and settings['resolution'] is missing or invalid. "
                    "Wavelengths array will be empty.",
                    UserWarning,
                    stacklevel=2,
                )
        # If wavelengths were loaded from cal_path and Headwall params were not present, they are kept.

    def __repr__(self):
        from pprint import pformat

        return (
            "settings = \n"
            + pformat(self.settings)
            + "\n\ncalibration = \n"
            + pformat(self.calibration)
        )

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_value, traceback):
        pass

    def dump(
        self, json_path: str = None, cal_path: str = None, use_pickle: bool = False
    ):
        """Save the settings and calibration files"""
        with open(
            self.json_path[:-5] + "_updated.json" if json_path is None else json_path,
            "w",
        ) as outfile:
            json.dump(
                self.settings,
                outfile,
                indent=4,
            )

        if use_pickle:  # must provide filename for pickle.
            warnings.warn(
                "Pickle calibration files are deprecated and will be removed in a "
                "future version. We sugesting using the .nc format using `.dump()` "
                "(which now saves to .nc by default).",
                DeprecationWarning,
                stacklevel=2,
            )
            with open(cal_path, "wb") as handle:
                pickle.dump(self.calibration, handle, protocol=4)
        else:
            self.save_calibration_data_to_netcdf(
                self.cal_path[:-3] + "_updated.nc" if cal_path is None else cal_path
            )

    def save_calibration_data_to_netcdf(self, filename):
        """
        Save the calibration data dictionary to a NetCDF file using xarray. Intended to be more portable then pickle.

        Parameters:
            filename (str): The filename to save to (NetCDF format).
        """

        attrs = {}
        ds_dict = {}

        for key, value in self.calibration.items():
            if isinstance(value, (int, float, str)):  # Handle attributes
                attrs[key] = value
            elif isinstance(value, xr.DataArray):  # Handle DataArrays
                ds_dict[key] = value
            elif isinstance(value, interp1d):  # Handle interp1d objects
                ds_dict[f"{key}_x"] = ((f"{key}_dim"), value.x)
                ds_dict[f"{key}_y"] = ((f"{key}_dim"), value.y)
                # Store kind attribute for interp1d
                attrs[f"{key}_kind"] = getattr(
                    value, "kind", "cubic"
                )  # Default if not found
            elif isinstance(value, np.ndarray):  # Handle numpy arrays
                dims = [
                    f"{key}_dim_{i}" for i in range(value.ndim)
                ]  # More generic dim naming
                ds_dict[key] = (dims, value)
            # else:
            #     warnings.warn(f"Unsupported data type for NetCDF storage: {type(value)} for key: '{key}'. Skipping.", UserWarning, stacklevel=2)

        # Create the xarray.Dataset
        try:
            ds = xr.Dataset(ds_dict, attrs=attrs)
        except Exception as e:
            print(
                f"Error creating Dataset for NetCDF. ds_dict keys: {list(ds_dict.keys())}, attrs keys: {list(attrs.keys())}. Error: {e}"
            )
            raise

        # Save to NetCDF with compression (adjust encoding if needed)
        encoding = {
            key_enc: {"zlib": True, "complevel": 4} for key_enc in ds_dict
        }  # Renamed key to key_enc
        try:
            ds.to_netcdf(filename, mode="w", encoding=encoding)
        finally:
            ds.close()  # Ensure dataset is closed

    def load_calibration_data_from_netcdf(self, filename):
        """
        Load the calibration data dictionary from a NetCDF file using xarray.

        Parameters:
            filename (str): The filename to load from (NetCDF format).

        Returns:
            dict: The loaded calibration data dictionary.
        """

        ds = xr.open_dataset(filename)
        data_dict = {}

        # Load attributes
        data_dict.update(ds.attrs)

        # Identify and reconstruct interp1d objects first
        interp1d_keys_reconstructed = set()  # To avoid double-adding components
        for attr_key in ds.attrs:
            if attr_key.endswith("_kind"):
                base_key = attr_key[:-5]
                x_var_name = f"{base_key}_x"
                y_var_name = f"{base_key}_y"
                if x_var_name in ds.data_vars and y_var_name in ds.data_vars:
                    x_data = ds[x_var_name].values
                    y_data = ds[y_var_name].values
                    kind_val = ds.attrs[attr_key]
                    data_dict[base_key] = interp1d(
                        x_data, y_data, kind=kind_val, fill_value="extrapolate"
                    )
                    interp1d_keys_reconstructed.add(x_var_name)
                    interp1d_keys_reconstructed.add(y_var_name)

        # Load remaining data variables (that are not part of reconstructed interp1d)
        for key, value in ds.items():  # ds.items() iterates over data_vars
            if key not in interp1d_keys_reconstructed:
                if isinstance(value, xr.DataArray):
                    # Special handling for 'rad_ref' to keep it as DataArray
                    if key == "rad_ref":
                        data_dict[key] = value.copy(
                            deep=True
                        )  # Copy to ensure it's not tied to open file
                    else:
                        data_dict[key] = value.values
                # else it might be a coordinate, which we don't typically store in self.calibration directly

        self.calibration = data_dict
        ds.close()


# %% ../nbs/api/data.ipynb XX (new cell or existing patch cell)
@patch
def headwall_software_crop(self: CameraProperties, x: np.ndarray) -> np.ndarray:
    """
    Crops the hardware-captured frame to the Headwall optical ROI,
    accounting for sensor vs. spectrometer orientation swap.
    Input x: from XIMEA camera, shape self.settings["hardware_capture_resolution"]
             (e.g., [XIMEA_Height=344, XIMEA_Width=1024])
    Output: frame oriented as Headwall [Spatial, Spectral]
            (e.g., [Headwall_Spatial_Size=1024, Headwall_Spectral_Size=343])
    """
    # (Keep the required_settings check and x.shape validation as before)
    required_settings = [
        "win_offset_y_hw_api",
        "win_offset_x_hw_api",
        "win_resolution_h_hw_api",
        "win_resolution_w_hw_api",
        "headwall_spatial_offset_fullsensor_px",
        "headwall_spectral_offset_fullsensor_px",
        "headwall_spatial_size_px",
        "headwall_spectral_size_px",
        "hardware_capture_resolution",
    ]
    for req_set in required_settings:
        if req_set not in self.settings:
            raise ValueError(
                f"Missing required setting '{req_set}' in JSON for headwall_software_crop."
            )

    ximea_frame_H, ximea_frame_W = x.shape  # e.g., (344, 1024)
    hw_capture_H_setting, hw_capture_W_setting = self.settings[
        "hardware_capture_resolution"
    ]
    if ximea_frame_H != hw_capture_H_setting or ximea_frame_W != hw_capture_W_setting:
        warnings.warn(
            f"Input frame shape {x.shape} to headwall_software_crop does not match "
            f"settings['hardware_capture_resolution'] {[hw_capture_H_setting, hw_capture_W_setting]}. Cropping may be incorrect.",
            UserWarning,
            stacklevel=2,
        )

    # XIMEA API hardware capture parameters (offsets of the captured window on the full sensor)
    ximea_hw_offset_y_on_sensor = self.settings[
        "win_offset_y_hw_api"
    ]  # Start Y of XIMEA capture window
    ximea_hw_offset_x_on_sensor = self.settings[
        "win_offset_x_hw_api"
    ]  # Start X of XIMEA capture window

    # Headwall's desired final ROI parameters (absolute offsets on the full sensor)
    headwall_spectral_start_abs_on_sensor = self.settings[
        "headwall_spectral_offset_fullsensor_px"
    ]  # e.g. 858 (Headwall Spectral)
    headwall_final_spectral_size = self.settings[
        "headwall_spectral_size_px"
    ]  # e.g. 343

    headwall_spatial_start_abs_on_sensor = self.settings[
        "headwall_spatial_offset_fullsensor_px"
    ]  # e.g. 472 (Headwall Spatial)
    headwall_final_spatial_size = self.settings["headwall_spatial_size_px"]  # e.g. 1024

    # Calculate slices *within the XIMEA hardware-captured frame `x`*

    # --- Slice for Headwall's SPECTRAL dimension ---
    # This is along XIMEA's Y-axis (x.shape[0], which is ximea_frame_H)
    # `start_offset_within_capture_Y` = (Absolute Headwall Spectral Start) - (XIMEA Capture Window Y Start)
    start_slice_y_for_spectral = (
        headwall_spectral_start_abs_on_sensor - ximea_hw_offset_y_on_sensor
    )
    end_slice_y_for_spectral = start_slice_y_for_spectral + headwall_final_spectral_size

    # Ensure slices are valid for the captured frame's Y dimension (ximea_frame_H)
    start_slice_y_for_spectral = max(0, start_slice_y_for_spectral)
    if not (
        0 <= start_slice_y_for_spectral < end_slice_y_for_spectral <= ximea_frame_H
    ):
        raise ValueError(
            f"Calculated Headwall SPECTRAL slice (for XIMEA Y-axis) [{start_slice_y_for_spectral}:{end_slice_y_for_spectral}] "
            f"is out of bounds for XIMEA hardware frame height {ximea_frame_H}. "
            f"Check JSON: headwall_spectral_offset/size vs win_offset_y_hw_api/win_resolution_h_hw_api."
        )

    # --- Slice for Headwall's SPATIAL dimension ---
    # This is along XIMEA's X-axis (x.shape[1], which is ximea_frame_W)
    # `start_offset_within_capture_X` = (Absolute Headwall Spatial Start) - (XIMEA Capture Window X Start)
    start_slice_x_for_spatial = (
        headwall_spatial_start_abs_on_sensor - ximea_hw_offset_x_on_sensor
    )
    end_slice_x_for_spatial = start_slice_x_for_spatial + headwall_final_spatial_size

    # Ensure slices are valid for the captured frame's X dimension (ximea_frame_W)
    start_slice_x_for_spatial = max(0, start_slice_x_for_spatial)
    if not (0 <= start_slice_x_for_spatial < end_slice_x_for_spatial <= ximea_frame_W):
        raise ValueError(
            f"Calculated Headwall SPATIAL slice (for XIMEA X-axis) [{start_slice_x_for_spatial}:{end_slice_x_for_spatial}] "
            f"is out of bounds for XIMEA hardware frame width {ximea_frame_W}. "
            f"Check JSON: headwall_spatial_offset/size vs win_offset_x_hw_api/win_resolution_w_hw_api."
        )

    # Crop the XIMEA frame according to its native orientation
    # x has shape (XIMEA_Height, XIMEA_Width)
    # Intermediate frame will have XIMEA Y as rows (Headwall Spectral) and XIMEA X as columns (Headwall Spatial)
    intermediate_cropped_frame = x[
        start_slice_y_for_spectral:end_slice_y_for_spectral,
        start_slice_x_for_spatial:end_slice_x_for_spatial,
    ]
    # Shape of intermediate_cropped_frame: (headwall_final_spectral_size, headwall_final_spatial_size)
    # e.g., (343, 1024)

    # Transpose to get Headwall's [Spatial, Spectral] orientation
    headwall_oriented_frame = intermediate_cropped_frame.T
    # Shape of headwall_oriented_frame: (headwall_final_spatial_size, headwall_final_spectral_size)
    # e.g., (1024, 343)

    expected_final_shape = tuple(self.settings["final_image_shape_after_crop"])
    if headwall_oriented_frame.shape != expected_final_shape:
        # This warning is important if adjustments were made due to slice validation
        warnings.warn(
            f"headwall_software_crop output shape {headwall_oriented_frame.shape} "
            f"does not match settings['final_image_shape_after_crop'] {expected_final_shape}. "
            f"This might be due to slice clipping if offsets were not perfectly aligned.",
            UserWarning,
            stacklevel=2,
        )

    return headwall_oriented_frame


# %% ../nbs/api/data.ipynb 23
@patch
def tfm_setup(
    self: CameraProperties,
    more_setup: Callable[[CameraProperties], None] = None,
    dtype: Union[np.uint8, np.uint16, np.float32] = np.uint16,
    lvl: int = 0,
):
    """Setup for transforms"""
    if self.fast_smile in self.tfm_list:
        self.smiled_size = (
            np.ptp(self.settings["row_slice"]),
            self.settings["resolution"][1] - np.max(self.calibration["smile_shifts"]),
        )
        self.line_buff = CircArrayBuffer(self.smiled_size, axis=0, dtype=dtype)

        # for collapsing spectral pixels into bands
        self.byte_sz = dtype(0).nbytes
        self.width = np.uint16(
            self.settings["fwhm_nm"]
            * self.settings["resolution"][1]
            / np.ptp(self.calibration["wavelengths_linear"])
        )
        self.bin_rows = np.ptp(self.settings["row_slice"])
        self.bin_cols = self.settings["resolution"][1] - np.max(
            self.calibration["smile_shifts"]
        )
        self.reduced_shape = (self.bin_rows, self.bin_cols // self.width, self.width)

    if self.fast_bin in self.tfm_list:
        self.binned_wavelengths = self.calibration["wavelengths_linear"].astype(
            np.float32
        )
        self.binned_wavelengths = np.lib.stride_tricks.as_strided(
            self.binned_wavelengths,
            strides=(self.width * 4, 4),  # assumed np.float32
            shape=(len(self.binned_wavelengths) // self.width, self.width),
        )
        self.binned_wavelengths = np.around(
            self.binned_wavelengths.mean(axis=1), decimals=1
        )

    if self.slow_bin in self.tfm_list:
        n_bands = int(
            np.ptp(self.calibration["wavelengths"]) // self.settings["fwhm_nm"]
        )
        # jump by `fwhm_nm` and find closest array index, then let the wavelengths be in the middle between jumps
        self.λs = np.around(
            np.array(
                [
                    np.min(self.calibration["wavelengths"])
                    + i * self.settings["fwhm_nm"]
                    for i in range(n_bands + 1)
                ]
            ),
            decimals=1,
        )
        self.bin_idxs = [
            np.argmin(np.abs(self.calibration["wavelengths"] - λ)) for λ in self.λs
        ]
        self.binned_wavelengths = self.λs[:-1] + self.settings["fwhm_nm"] // 2  #
        binned_type = np.float32 if hasattr(self, "need_rad") else dtype
        self.bin_buff = CircArrayBuffer(
            (np.ptp(self.settings["row_slice"]), n_bands), axis=1, dtype=binned_type
        )

    if self.dn2rad in self.tfm_list:
        # precompute some reference data for converting digital number to radiance
        self.nearest_exposure = (
            self.calibration["rad_ref"]
            .sel(exposure=self.settings["exposure_ms"], method="nearest")
            .exposure
        )

        # use max valid rad_ref luminance if none given.
        if "luminance" not in self.settings.keys():
            self.settings["luminance"] = int(
                np.max(
                    self.calibration["rad_ref"].luminance.where(
                        np.isfinite(
                            self.calibration["rad_ref"]
                            .sel(exposure=self.nearest_exposure)
                            .any(axis=(1, 2))
                        )
                    )
                ).data.tolist()
            )

        try:
            dark_radref = (
                self.calibration["rad_ref"]
                .sel(exposure=self.nearest_exposure, luminance=0)
                .isel(luminance=0)
            )
        except (KeyError, ValueError):
            dark_radref = self.calibration["rad_ref"].sel(
                exposure=self.nearest_exposure, luminance=0
            )

        self.dark_current = np.squeeze(
            np.array(self.settings["exposure_ms"] / self.nearest_exposure * dark_radref)
        )
        self.ref_luminance = np.squeeze(
            np.array(
                self.settings["exposure_ms"]
                / self.nearest_exposure
                * self.calibration["rad_ref"].sel(
                    exposure=self.nearest_exposure, luminance=self.settings["luminance"]
                )
                - self.dark_current
            )
        )
        self.spec_rad_ref = np.float32(
            self.calibration["sfit"](self.calibration["wavelengths"])
        )

        self.dark_current = np.float32(self.fast_smile(self.dark_current))
        self.ref_luminance = np.float32(self.fast_smile(self.ref_luminance))

    if hasattr(self, "need_rad_after_fast_bin"):
        self.dark_current = np.float32(self.fast_bin(self.dark_current))
        self.ref_luminance = np.float32(self.fast_bin(self.ref_luminance))
        self.spec_rad_ref = np.float32(
            self.calibration["sfit"](self.binned_wavelengths)
        )

    if hasattr(self, "need_rad_after_slow_bin"):
        self.dark_current = np.float32(self.slow_bin(self.dark_current))
        self.ref_luminance = np.float32(self.slow_bin(self.ref_luminance))
        self.spec_rad_ref = np.float32(
            self.calibration["sfit"](self.binned_wavelengths)
        )

    # --- DEBUG PRINTS ---
    print(
        f"DEBUG tfm_setup: Current processing_lvl = {lvl}"
    )  # lvl is passed to tfm_setup
    print(
        f"DEBUG tfm_setup: self.tfm_list = {[f.__name__ for f in self.tfm_list]}"
    )  # Show names of functions in tfm_list

    if self.dn2rad in self.tfm_list:  # Only print these if dn2rad is active
        print(
            f"  DEBUG tfm_setup: self.nearest_exposure = {getattr(self, 'nearest_exposure', 'Not Set')}"
        )
        print(
            f"  DEBUG tfm_setup: self.settings['exposure_ms'] = {self.settings.get('exposure_ms', 'Not Set')}"
        )
        print(
            f"  DEBUG tfm_setup: self.settings['luminance'] (for rad_ref selection) = {self.settings.get('luminance', 'Not Set')}"
        )

        dark_current_sample = getattr(self, "dark_current", None)
        if dark_current_sample is not None and dark_current_sample.ndim == 2:
            print(
                f"  DEBUG tfm_setup: self.dark_current (sample) = {dark_current_sample[0, :5]}"
            )
        else:
            print(f"  DEBUG tfm_setup: self.dark_current = {dark_current_sample}")

        ref_luminance_sample = getattr(self, "ref_luminance", None)
        if ref_luminance_sample is not None and ref_luminance_sample.ndim == 2:
            print(
                f"  DEBUG tfm_setup: self.ref_luminance (sample) = {ref_luminance_sample[0, :5]}"
            )
        else:
            print(f"  DEBUG tfm_setup: self.ref_luminance = {ref_luminance_sample}")

        print(
            f"  DEBUG tfm_setup: self.calibration['spec_rad_ref_luminance'] = {self.calibration.get('spec_rad_ref_luminance', 'Not Found')}"
        )

        mean_ref_lum_val = (
            np.mean(ref_luminance_sample) if ref_luminance_sample is not None else 0
        )
        if mean_ref_lum_val != 0:
            scaling_factor = self.settings.get("luminance", 1) / mean_ref_lum_val
            print(
                f"  DEBUG tfm_setup: scaling factor (lum/ref_lum) approx = {scaling_factor}"
            )
        else:
            print(
                f"  DEBUG tfm_setup: scaling factor (lum/ref_lum) approx = Undefined (ref_luminance is zero or None)"
            )

    if self.rad2ref_6SV in self.tfm_list:
        self.rad_6SV = np.float32(self.calibration["rad_fit"](self.binned_wavelengths))

    if more_setup is not None:
        more_setup(self)


# %% ../nbs/api/data.ipynb 24
@patch
def crop(self: CameraProperties, x: np.ndarray) -> np.ndarray:
    """Crops to illuminated area"""
    return x[self.settings["row_slice"][0] : self.settings["row_slice"][1], :]


# %% ../nbs/api/data.ipynb 25
@patch
def fast_smile(self: CameraProperties, x: np.ndarray) -> np.ndarray:
    """Apply the fast smile correction procedure"""
    for i in range(self.smiled_size[0]):
        self.line_buff.put(
            x[
                i,
                self.calibration["smile_shifts"][i] : self.calibration["smile_shifts"][
                    i
                ]
                + self.smiled_size[1],
            ]
        )
    return self.line_buff.data


# %% ../nbs/api/data.ipynb 26
@patch
def fast_bin(self: CameraProperties, x: np.ndarray) -> np.ndarray:
    """Changes the view of the datacube so that everything that needs to be binned is in the last axis. The last axis is then binned."""
    byte_sz = x.itemsize
    buff = np.lib.stride_tricks.as_strided(
        x,
        shape=self.reduced_shape,
        strides=(self.bin_cols * byte_sz, self.width * byte_sz, byte_sz),
    )
    return buff.sum(axis=-1)


# %% ../nbs/api/data.ipynb 27
@patch
def slow_bin(self: CameraProperties, x: np.ndarray) -> np.ndarray:
    """Bins spectral bands accounting for the slight nonlinearity in the index-wavelength map"""
    for i in range(len(self.bin_idxs) - 1):
        self.bin_buff.put(
            np.float32(x[:, self.bin_idxs[i] : self.bin_idxs[i + 1]]).sum(axis=1)
        )
    return self.bin_buff.data


# %% ../nbs/api/data.ipynb 28
@patch
def dn2rad(
    self: CameraProperties, x: "Array['λ,x',np.uint16]"
) -> "Array['λ,x',np.float32]":
    """Converts digital numbers to radiance (uW/cm^2/sr/nm). Use after cropping to useable area."""

    return (
        (np.float32(x) - self.dark_current)
        * self.settings["luminance"]
        / self.ref_luminance
        * self.spec_rad_ref
        / self.calibration["spec_rad_ref_luminance"]
    )


# %% ../nbs/api/data.ipynb 29
@patch
def rad2ref_6SV(
    self: CameraProperties, x: "Array['λ,x',np.float32]"
) -> "Array['λ,x',np.float32]":
    """"""
    # # If wavelength dimension shapes do not match, do some hacks
    # if x.shape[1] < self.rad_6SV.shape[0]:   # use wavelengths after binning to match input
    #     self.rad_6SV = np.float32(self.calibration["rad_fit"](self.binned_wavelengths))
    # elif x.shape[1] < self.rad_6SV.shape[0]: # upsize wavelength range to match input
    #     self.rad_6SV = np.float64(self.calibration["rad_fit"]( np.resize(self.calibration["wavelengths"],x.shape[1]) ))

    return x / self.rad_6SV


# %% ../nbs/api/data.ipynb 30 (Modify this cell)
@patch
def set_processing_lvl(
    self: CameraProperties,
    lvl: int = -1,
    custom_tfms: List[Callable[[np.ndarray], np.ndarray]] = None,
):
    """Define the output `lvl` of the transform pipeline.
    Includes Headwall-specific initial software cropping if applicable.
    -1: do not apply any transforms (default),
    0 : raw digital numbers cropped to useable sensor area,
    1 : crop + fast smile,
    2 : crop + fast smile + fast binning,
    3 : crop + fast smile + slow binning,
    4 : crop + fast smile + fast binning + conversion to radiance in units of uW/cm^2/sr/nm,
    5 : crop + fast smile + radiance + fast binning,
    6 : crop + fast smile + fast binning + radiance + reflectance,
    7 : crop + fast smile + radiance + slow binning,
    8 : crop + fast smile + radiance + slow binning + reflectance.
    """
    # Determine if headwall_software_crop method exists and should be used
    use_headwall_crop = (
        hasattr(self, "headwall_software_crop")
        and "headwall_pixel_dispersion_nm_px" in self.settings
    )  # Proxy for Headwall config

    base_tfms = []
    if use_headwall_crop:
        base_tfms.append(self.headwall_software_crop)

    # Standard OpenHSI crop based on row_slice (operates on output of headwall_crop if used)
    # This crop should always be applied if lvl >= 0, after headwall_crop
    if lvl >= 0:  # For lvl 0 and above, apply the standard row_slice crop
        base_tfms.append(self.crop)

    if lvl == -1:
        # For lvl -1, if use_headwall_crop is true, only headwall_crop is applied.
        # If not using headwall_crop, tfm_list is empty.
        self.tfm_list = [self.headwall_software_crop] if use_headwall_crop else []
    elif lvl == 0:
        self.tfm_list = base_tfms  # e.g., [headwall_crop, crop] or just [crop]
    elif lvl == 1:
        self.tfm_list = base_tfms + [self.fast_smile]
    elif lvl == 2:
        self.tfm_list = base_tfms + [self.fast_smile, self.fast_bin]
    elif lvl == 3:
        self.tfm_list = base_tfms + [self.fast_smile, self.slow_bin]
    elif lvl == 4:
        self.tfm_list = base_tfms + [self.fast_smile, self.fast_bin, self.dn2rad]
        self.need_rad_after_fast_bin = True
    elif lvl == 5:
        self.tfm_list = base_tfms + [self.fast_smile, self.dn2rad, self.fast_bin]
    elif lvl == 6:
        self.tfm_list = base_tfms + [
            self.fast_smile,
            self.fast_bin,
            self.dn2rad,
            self.rad2ref_6SV,
        ]
        self.need_rad_after_fast_bin = True
    elif lvl == 7:
        self.tfm_list = base_tfms + [self.fast_smile, self.dn2rad, self.slow_bin]
    elif lvl == 8:
        self.tfm_list = base_tfms + [
            self.fast_smile,
            self.dn2rad,
            self.slow_bin,
            self.rad2ref_6SV,
        ]
    else:  # Should not happen if lvl is one of the above
        self.tfm_list = base_tfms  # Fallback for unrecognized positive lvl

    if custom_tfms is not None:
        # Custom transforms usually replace the entire pipeline, or are appended.
        # For now, assume they replace. User can prepend base_tfms manually if needed.
        self.tfm_list = listify(custom_tfms)

    # Determine input/output data types
    if "pixel_format" in self.settings:
        pixel_fmt_str = str(
            self.settings["pixel_format"]
        ).lower()  # Ensure string and lower
        if any(sub in pixel_fmt_str for sub in ["mono8", "8bit", "8"]):
            self.dtype_in = np.uint8
        elif any(
            sub in pixel_fmt_str
            for sub in [
                "mono12",
                "12bit",
                "12",
                "mono10",
                "10bit",
                "10",
                "mono16",
                "16bit",
                "16",
            ]
        ):
            self.dtype_in = np.uint16
        else:
            self.dtype_in = np.uint16  # Default for unrecognized
            warnings.warn(
                f"Unrecognized pixel_format '{self.settings['pixel_format']}'. Defaulting dtype_in to np.uint16.",
                UserWarning,
                stacklevel=2,
            )
    else:
        self.dtype_in = np.uint16  # Default if not specified

    self.dtype_out = (
        np.float32
        if lvl in (4, 5, 6, 7, 8)
        or (self.fast_bin in self.tfm_list and lvl in (2,))
        or (self.slow_bin in self.tfm_list and lvl in (3,))
        else self.dtype_in
    )

    # Initialize transform setup and determine final datacube shape (self.dc_shape)
    if len(self.tfm_list) > 0:
        # Frame shape for testing the pipeline (input to the *first* transform)
        # This should be the raw hardware capture resolution if headwall_software_crop is used.
        if use_headwall_crop and self.headwall_software_crop == self.tfm_list[0]:
            initial_frame_shape = tuple(
                self.settings.get("hardware_capture_resolution", (0, 0))
            )
            if initial_frame_shape == (0, 0):  # Fallback if not in settings
                warnings.warn(
                    "`hardware_capture_resolution` not in settings. Attempting to use "
                    "`flat_field_pic` shape for pipeline test, which might be incorrect.",
                    UserWarning,
                    stacklevel=2,
                )
                initial_frame_shape = self.calibration.get(
                    "flat_field_pic", np.zeros((1, 1))
                ).shape

        elif (
            self.crop == self.tfm_list[0] and not use_headwall_crop
        ):  # `crop` is first, needs full sensor resolution ideally
            # This case is for non-Headwall cameras where `self.crop` is the first step.
            # `self.settings["resolution"]` is POST-CROP. We need pre-crop shape.
            # This relies on `flat_field_pic` being the full sensor image before OpenHSI's `self.crop`.
            initial_frame_shape = self.calibration.get(
                "flat_field_pic",
                np.zeros(
                    tuple(self.settings.get("resolution_full_sensor", (1, 1))),
                    dtype=self.dtype_in,
                ),
            ).shape
            if (
                initial_frame_shape == (1, 1)
                and "resolution_full_sensor" not in self.settings
            ):
                warnings.warn(
                    "Full sensor resolution not available for pipeline test. dc_shape may be incorrect.",
                    UserWarning,
                    stacklevel=2,
                )

        else:  # No crop or unknown first transform, assume it takes `self.settings["resolution"]`
            # This might occur if custom_tfms are used without headwall_software_crop or crop.
            initial_frame_shape = tuple(self.settings.get("resolution", (1, 1)))
            if initial_frame_shape == (1, 1):
                warnings.warn(
                    "Using settings['resolution'] for pipeline test. Ensure this is correct for the first transform.",
                    UserWarning,
                    stacklevel=2,
                )

        if not (
            len(initial_frame_shape) == 2
            and initial_frame_shape[0] > 0
            and initial_frame_shape[1] > 0
        ):
            raise ValueError(
                f"Invalid initial_frame_shape for pipeline test: {initial_frame_shape}. Check settings."
            )

        test_frame_for_pipeline = np.zeros(initial_frame_shape, dtype=self.dtype_in)

        # tfm_setup uses self.settings["resolution"] (which should be POST headwall_software_crop & self.crop)
        # for calculations like smile_shifts array length, binning parameters, etc.
        # Ensure self.settings["resolution"] is correctly set in the JSON to the final 2D frame shape
        # *before* along-track dimension is added.
        if "resolution" not in self.settings:
            raise ValueError(
                "`self.settings['resolution']` (final 2D frame shape post-initial-crops) must be defined for tfm_setup."
            )

        self.tfm_setup(dtype=self.dtype_in, lvl=lvl)  # Call tfm_setup

        self.dc_shape = self.pipeline(
            test_frame_for_pipeline
        ).shape  # Final 2D shape after all transforms

    elif (
        "resolution" in self.settings.keys()
    ):  # No transforms, dc_shape is the one from settings
        self.dc_shape = tuple(self.settings["resolution"])
    else:  # Absolute fallback
        self.dc_shape = (1, 1)
        warnings.warn(
            "Could not determine dc_shape. Defaulting to (1,1).",
            UserWarning,
            stacklevel=2,
        )

    print(
        f"CameraProperties.set_processing_lvl (lvl={lvl}): tfm_list={[f.__name__ for f in self.tfm_list]}, final 2D dc_shape={self.dc_shape}"
    )


# %% ../nbs/api/data.ipynb 33
@patch
def pipeline(self: CameraProperties, x: np.ndarray) -> np.ndarray:
    """Compose a list of transforms and apply to x."""
    for f in self.tfm_list:
        x = f(x)
    return x


# %% ../nbs/api/data.ipynb 36
class DateTimeBuffer:
    """Records timestamps in UTC time."""

    def __init__(self, n: int = 16):
        """Initialise a nx1 array and write index"""
        self.data = np.arange(n).astype(datetime)
        self.n = n
        self.write_pos = 0

    def __getitem__(self, key: slice) -> datetime:
        return self.data[key]

    def update(self):
        """Stores current UTC time in an internal buffer when this method is called."""
        ts = datetime.timestamp(datetime.now())
        self.data[self.write_pos] = datetime.fromtimestamp(ts, tz=timezone.utc)
        self.write_pos += 1

        # Loop back if buffer is full
        if self.write_pos == self.n:
            self.write_pos = 0


# %% ../nbs/api/data.ipynb 40
from functools import reduce
import psutil


# %% ../nbs/api/data.ipynb 41
@delegates()
class DataCube(CameraProperties):
    """Facilitates the collection, viewing, and saving of hyperspectral datacubes."""

    def __init__(
        self,
        n_lines: int = 16,  # How many along-track pixels desired
        processing_lvl: int = -1,  # Desired real time processing level
        warn_mem_use: bool = True,  # Raise error if trying to allocate too much memory (> 80% of available RAM)
        **kwargs,
    ):
        """Preallocate array buffers"""
        self.n_lines = n_lines
        self.proc_lvl = processing_lvl
        super().__init__(**kwargs)
        self.set_processing_lvl(processing_lvl)

        self.timestamps = DateTimeBuffer(n_lines)
        self.dc_shape = (self.dc_shape[0], self.n_lines, self.dc_shape[1])
        mem_sz = (
            self.dtype_out(0).nbytes * reduce(lambda x, y: x * y, self.dc_shape) / 2**20
        )  # MB
        mem_thresh = (
            0.8 * psutil.virtual_memory().available / 2**20
        )  # 80% of available memory in MB
        if (
            warn_mem_use
            and mem_sz > mem_thresh
            and input(
                f"{mem_sz:.02f} MB of RAM will be allocated. You have {mem_thresh/.8:.2f} MB available. Continue? [y/n]"
            )
            != "y"
        ):
            raise RuntimeError(
                f"""Datacube memory allocation ({mem_sz:.02f} MB) exceeded >80% available RAM ({mem_thresh/.8:.2f} MB). 
            Halted by user (did not receive `y` at prompt). 
            To proceed, you can let `warn_mem_use=False`, decrease `n_lines`, use a `processing_lvl`>=2 
            that includes binning, or continue anyway by entering `y` at the prompt."""
            )
        if self.dc_shape[0] > 1:
            print(
                f"Allocated {mem_sz:.02f} MB of RAM. There was {mem_thresh/.8:.2f} MB available."
            )
        self.dc = CircArrayBuffer(size=self.dc_shape, axis=1, dtype=self.dtype_out)

    def __repr__(self):
        return (
            f"DataCube: shape = {self.dc_shape}, Processing level = {self.proc_lvl}\n"
        )


# %% ../nbs/api/data.ipynb 42
@patch
def put(
    self: DataCube, x: np.ndarray, camera_timestamp_sec: float = None
):  # Add new optional arg
    """Applies the composed tranforms and writes the 2D array into the data cube. Stores a timestamp for each push."""
    if camera_timestamp_sec is not None:
        # Convert the float timestamp (seconds since epoch) to datetime object
        # Ensure it's UTC, as XIMEA timestamps are usually UTC or relative to a UTC-synced clock
        dt_obj = datetime.fromtimestamp(camera_timestamp_sec, tz=timezone.utc)

        # Store directly into the DateTimeBuffer's data array
        # This bypasses DateTimeBuffer.update() which uses datetime.now()
        if self.timestamps.write_pos < self.timestamps.n:
            self.timestamps.data[self.timestamps.write_pos] = dt_obj
            self.timestamps.write_pos += 1
            if (
                self.timestamps.write_pos == self.timestamps.n
            ):  # Loop back if buffer is full
                self.timestamps.write_pos = 0
        else:  # Should not happen if DateTimeBuffer is sized correctly for n_lines
            self.timestamps.update()  # Fallback, though ideally sized correctly
    else:
        self.timestamps.update()  # Original behavior if no camera_timestamp is passed

    self.dc.put(self.pipeline(x))


# %% ../nbs/api/data.ipynb 43 (REPLACE THIS ENTIRE PATCHED METHOD)
@patch
def save(
    self: DataCube,
    save_dir: str,  # Path to folder where all datacubes will be saved at
    preconfig_meta_path: str = None,  # Path to a .json file that includes metadata fields to be saved inside datacube
    prefix: str = "",  # Prepend a custom prefix to your file name
    suffix: str = "",  # Append a custom suffix to your file name
    old_style: bool = False,  # Order of axis (True: [X,Y,Wavelength], False: [Wavelength,X,Y])
    save_preview: bool = False,  # Control whether to save a preview image
):
    """Saves to a NetCDF file (and optionally an RGB representation) to directory dir_path in folder given by date with file name given by UTC time."""
    if preconfig_meta_path is not None:
        try:
            with open(preconfig_meta_path) as json_file:
                attrs = json.load(json_file)
        except FileNotFoundError:
            print(
                f"Warning: Preconfigured metadata file not found: {preconfig_meta_path}. Using empty attributes."
            )
            attrs = {}
        except json.JSONDecodeError:
            print(
                f"Warning: Could not decode preconfigured metadata JSON: {preconfig_meta_path}. Using empty attributes."
            )
            attrs = {}
    else:
        attrs = {}

    # Merge with any existing ds_metadata (e.g., from a loaded NetCDF)
    if hasattr(self, "ds_metadata") and isinstance(self.ds_metadata, dict):
        attrs.update(
            self.ds_metadata
        )  # ds_metadata can override preconfig_meta if keys clash

    # Add camera settings to attributes, prefixing with 'setting_' to avoid clashes
    if hasattr(self, "settings") and isinstance(self.settings, dict):
        for key, value in self.settings.items():
            # Only add if value is simple type suitable for NetCDF attribute
            if isinstance(value, (str, int, float, bool, list, tuple)):
                # Check if list/tuple contains only simple types
                if isinstance(value, (list, tuple)) and not all(
                    isinstance(i, (str, int, float, bool)) for i in value
                ):
                    continue  # Skip complex lists/tuples
                attrs[f"setting_{key}"] = value

    self.directory = Path(save_dir)
    # self.directory = Path(f"{save_dir}/{self.timestamps.data[0].strftime('%Y_%m_%d')}/")
    self.directory.mkdir(parents=True, exist_ok=True)
    # self.directory = f"{save_dir}/{self.timestamps[0].strftime('%Y_%m_%d')}" # Path object handles this

    # --- Corrected Wavelength Selection Logic ---
    # self.dc.data.shape[2] is the spectral dimension of the data in the buffer
    # For lvl=-1/0, this is headwall_spectral_size_px (e.g., 343)

    current_spectral_dim_size = self.dc.data.shape[2]
    wavelengths_for_nc = None

    if (
        hasattr(self, "binned_wavelengths")
        and isinstance(self.binned_wavelengths, np.ndarray)
        and len(self.binned_wavelengths) == current_spectral_dim_size
    ):
        wavelengths_for_nc = self.binned_wavelengths
        print(
            f"DEBUG DataCube.save: Using self.binned_wavelengths (len {len(wavelengths_for_nc)}) for NetCDF."
        )
    elif (
        "wavelengths" in self.calibration
        and isinstance(self.calibration["wavelengths"], np.ndarray)
        and len(self.calibration["wavelengths"]) == current_spectral_dim_size
    ):
        wavelengths_for_nc = self.calibration["wavelengths"]

    else:
        wavelengths_for_nc = np.arange(current_spectral_dim_size)
        warnings.warn(
            f"Wavelength data for NetCDF saving is falling back to np.arange({current_spectral_dim_size}). "
            f"Details: hasattr(binned_wavelengths): {hasattr(self, 'binned_wavelengths')}, "
            f"len(binned_wavelengths if hasattr): {len(self.binned_wavelengths) if hasattr(self, 'binned_wavelengths') else 'N/A'}, "
            f"calibration['wavelengths'] exists: {'wavelengths' in self.calibration}, "
            f"len(calibration['wavelengths'] if present): {len(self.calibration.get('wavelengths', []))}, "
            f"Expected spectral dim: {current_spectral_dim_size}.",
            UserWarning,
            stacklevel=2,
        )
    # Define coordinates for the NetCDF file
    # self.dc.data.shape[0] is the spatial/cross-track dimension (e.g., 1024 or 1023)
    # self.dc.data.shape[1] is the along-track dimension (n_lines)

    coords_dict = {
        "wavelength": (["wavelength"], wavelengths_for_nc),
        "x": (["x"], np.arange(self.dc.data.shape[0])),  # Cross-track / Spatial
        "y": (["y"], np.arange(self.dc.data.shape[1])),  # Along-track
        "time": (
            ["time"],
            self.timestamps.data.astype("datetime64[ns]"),
        ),  # Ensure nanosecond precision for xarray
    }

    if (
        hasattr(self, "cam_temperatures")
        and self.cam_temperatures.data.shape[0] == self.dc.data.shape[1]
    ):
        coords_dict["temperature"] = (
            ["y"],
            self.cam_temperatures.data,
        )  # Temperature indexed by along-track 'y'

    # Create the xarray Dataset
    # The `self.dc.data` is (cross_track, along_track, spectral_from_pipeline)
    # For old_style=False (default, preferred for ENVI/QGIS), we want (wavelength, cross_track, along_track)
    # For old_style=True, we want (cross_track, along_track, wavelength) which is what dc.data already is.

    if old_style:
        # Data is already [cross-track, along-track, wavelength_idx_from_pipeline]
        # We need to map wavelength_idx_from_pipeline to the actual wavelengths for the coordinate.
        # The coordinate names in data_vars must match those in coords_dict.
        data_array = self.dc.data
        dims = ["x", "y", "wavelength"]
    else:
        # Data is [cross-track, along_track, wavelength_idx_from_pipeline]
        # Transpose to [wavelength_idx_from_pipeline, cross-track, along_track] for saving
        data_array = np.moveaxis(self.dc.data, -1, 0)
        dims = ["wavelength", "x", "y"]

    self.nc = xr.Dataset(
        data_vars={"datacube": (dims, data_array)}, coords=coords_dict, attrs=attrs
    )

    # Add metadata to coordinates
    self.nc.x.attrs.update(
        {
            "long_name": "cross-track",
            "units": "pixels",
            "description": "Cross-track spatial coordinate (Headwall spatial dimension)",
        }
    )
    self.nc.y.attrs.update(
        {
            "long_name": "along-track",
            "units": "pixels",
            "description": "Along-track scan dimension",
        }
    )
    self.nc.time.attrs.update(
        {"long_name": "UTC time", "description": "Timestamp for each along-track line"}
    )
    self.nc.wavelength.attrs.update(
        {
            "long_name": "wavelength",
            "units": "nm",
            "description": "Center wavelength of spectral band in nanometers.",
        }
    )
    if "temperature" in self.nc.coords:
        self.nc.temperature.attrs.update(
            {
                "long_name": "camera_sensor_temperature",
                "units": "degrees Celsius",
                "description": "Temperature of camera sensor at time of image capture line.",
            }
        )

    # Add metadata to the datacube variable itself
    self.nc.datacube.attrs["long_name"] = "hyperspectral_datacube"
    self.nc.datacube.attrs["description"] = "Processed hyperspectral datacube"
    if self.proc_lvl in (4, 5, 7):
        self.nc.datacube.attrs["units"] = "uW/cm^2/sr/nm"
    elif self.proc_lvl in (6, 8):
        self.nc.datacube.attrs["units"] = "percentage_reflectance"
    else:
        self.nc.datacube.attrs["units"] = "digital_number"

    # Define filename
    filename_stem = (
        f"{prefix}{self.timestamps.data[0].strftime('%Y_%m_%d-%H_%M_%S')}{suffix}"
    )
    nc_filepath = self.directory / (filename_stem + ".nc")

    # Save NetCDF
    try:
        self.nc.to_netcdf(nc_filepath)
        print(f"  HYPER: Successfully saved NetCDF: {nc_filepath}")
    except Exception as e:
        print(f"ERROR DataCube.save: Failed to save NetCDF: {e}")
        import traceback

        traceback.print_exc()

    # Save preview image if requested
    if save_preview:
        try:
            png_filepath = self.directory / (filename_stem + ".png")
            fig = self.show(
                "matplotlib", hist_eq=True, quick_imshow=True
            )  # Pass plot_lib explicitly
            fig.savefig(png_filepath, bbox_inches="tight", pad_inches=0)
            plt.close(fig)  # Close the figure to free memory
            print(f"  HYPER: Successfully saved preview PNG: {png_filepath}")
        except Exception as e:
            print(f"ERROR DataCube.save: Failed to save preview PNG: {e}")


# %% ../nbs/api/data.ipynb 44
@patch
def load_nc(
    self: DataCube,
    nc_path: str,  # Path to a NetCDF4 file
    old_style: bool = False,  # Only for backwards compatibility for datacubes created before first release
    warn_mem_use: bool = True,  # Raise error if trying to allocate too much memory (> 80% of available RAM)
):
    """Lazy load a NetCDF datacube into the DataCube buffer."""
    with xr.open_dataset(nc_path) as ds:

        mem_sz = 4 * reduce(lambda x, y: x * y, ds.datacube.shape) / 2**20  # MB
        mem_thresh = (
            0.8 * psutil.virtual_memory().available / 2**20
        )  # 80% of available memory in MB
        if (
            warn_mem_use
            and mem_sz > mem_thresh
            and input(
                f"{mem_sz:.02f} MB of RAM will be allocated. You have {mem_thresh/.8:.2f} MB available. Continue? [y/n]"
            )
            != "y"
        ):
            raise RuntimeError(
                f"""Datacube load buffer memory allocation ({mem_sz:.02f} MB) exceeded >80% available RAM ({mem_thresh/.8:.2f} MB). 
            Halted by user (did not receive `y` at prompt). To proceed, you can let `warn_mem_use=False`, or continue anyway by entering `y` at the prompt."""
            )

        if old_style:  # cross-track, along-track, wavelength
            self.dc = CircArrayBuffer(
                size=ds.datacube.shape,
                axis=1,
                dtype=type(np.array(ds.datacube[0, 0])[0]),
            )
            self.dc.data = np.array(ds.datacube)
        else:  # wavelength, cross-track, along-track -> convert to old_style (datacube inserts do not need transpose)
            shape = (*ds.datacube.shape[1:], ds.datacube.shape[0])
            self.dc = CircArrayBuffer(
                size=shape, axis=1, dtype=type(np.array(ds.datacube[0, 0])[0])
            )
            self.dc.data = np.moveaxis(np.array(ds.datacube), 0, -1)
        print(
            f"Allocated {mem_sz:.02f} MB of RAM for the load buffer. There was {mem_thresh/.8:.2f} MB available."
        )

        self.ds_timestamps = (
            ds.time.to_numpy()
        )  # type is np.datetime64. convert to datetime.datetime
        unix_epoch = np.datetime64(0, "s")
        one_second = np.timedelta64(1, "s")
        seconds_since_epoch = (self.ds_timestamps - unix_epoch) / one_second
        self.ds_timestamps = np.array(
            [datetime.utcfromtimestamp(s) for s in seconds_since_epoch]
        )
        self.timestamps.data = self.ds_timestamps
        self.ds_metadata = ds.attrs

        if hasattr(ds, "temperature"):
            self.ds_temperatures = ds.temperature.to_numpy()
            self.cam_temperatures = CircArrayBuffer(
                size=self.ds_temperatures.shape, dtype=np.float32
            )
            self.cam_temperatures.data = self.ds_temperatures
        self.binned_wavelengths = np.array(ds.wavelength)
        self.dc.slots_left = 0  # indicate that the data buffer is full


# %% ../nbs/api/data.ipynb 45
@patch
def show(
    self: DataCube,
    plot_lib: str = "bokeh",  # Plotting backend. This can be 'bokeh' or 'matplotlib'
    red_nm: float = 640.0,  # Wavelength in nm to use as the red
    green_nm: float = 550.0,  # Wavelength in nm to use as the green
    blue_nm: float = 470.0,  # Wavelength in nm to use as the blue
    robust: Union[
        bool, int
    ] = False,  # Saturated linear stretch. E.g. setting `robust` to 2 will show the 2-98% percentile. Setting to `True` will default to `robust`=2. Robust to outliers
    hist_eq: bool = False,  # Choose to plot using histogram equilisation
    quick_imshow: bool = False,  # Used to skip holoviews and use matplotlib for a static plot
) -> "Image":  # a bokeh or matplotlib plot
    """Generate an RGB image from chosen RGB wavelengths with histogram equalisation or percentile options.
    The plotting backend can be specified by `plot_lib` and can be "bokeh" or "matplotlib".
    `quick_imshow` is used for saving figures quickly but cannot be used to make interactive plots.
    """

    rgb = np.zeros((*self.dc.data.shape[:2], 3), dtype=np.float32)
    if hasattr(self, "binned_wavelengths"):
        rgb[..., 0] = self.dc.data[
            :, :, np.argmin(np.abs(self.binned_wavelengths - red_nm))
        ]
        rgb[..., 1] = self.dc.data[
            :, :, np.argmin(np.abs(self.binned_wavelengths - green_nm))
        ]
        rgb[..., 2] = self.dc.data[
            :, :, np.argmin(np.abs(self.binned_wavelengths - blue_nm))
        ]
    else:
        rgb[..., 0] = self.dc.data[:, :, int(self.dc.data.shape[2] / 2)]
        rgb[..., 1] = self.dc.data[:, :, int(self.dc.data.shape[2] / 2)]
        rgb[..., 2] = self.dc.data[:, :, int(self.dc.data.shape[2] / 2)]

    if robust and not hist_eq:  # scale everything to the a saturated percentile
        if type(robust) is bool:
            robust = 2
        vmax = np.nanpercentile(rgb, 100 - robust)
        vmin = np.nanpercentile(rgb, robust)
        rgb = ((rgb.astype("f8") - vmin) / (vmax - vmin)).astype("f4")
        rgb = np.minimum(np.maximum(rgb, 0), 1)
    elif hist_eq and not robust:
        img_hist, bins = np.histogram(rgb.flatten(), 256, density=True)
        cdf = img_hist.cumsum()  # cumulative distribution function
        cdf = 1.0 * cdf / cdf[-1]  # normalize
        img_eq = np.interp(
            rgb.flatten(), bins[:-1], cdf
        )  # find new pixel values from linear interpolation of cdf
        rgb = img_eq.reshape(rgb.shape)
    elif robust and hist_eq:
        warnings.warn(
            "Cannot mix robust with histogram equalisation. No RGB adjustments will be made.",
            stacklevel=2,
        )
        rgb /= np.max(rgb)
    else:
        rgb /= np.max(rgb)

    if quick_imshow:
        fig, ax = plt.subplots(figsize=(12, 3))
        ax.imshow(rgb, aspect="equal")
        ax.set_xlabel("along-track")
        ax.set_ylabel("cross-track")
        return fig

    import holoviews as hv

    hv.extension(plot_lib, logo=False)
    rgb_hv = hv.RGB(
        (
            np.arange(rgb.shape[1]),
            np.arange(rgb.shape[0]),
            rgb[:, :, 0],
            rgb[:, :, 1],
            rgb[:, :, 2],
        )
    )

    if plot_lib == "bokeh":
        return rgb_hv.opts(
            width=1000, height=250, frame_height=int(rgb.shape[0] // 3)
        ).opts(xlabel="along-track", ylabel="cross-track", invert_yaxis=True)
    else:  # plot_lib == "matplotlib"
        return rgb_hv.opts(fig_inches=22).opts(
            xlabel="along-track", ylabel="cross-track", invert_yaxis=True
        )